{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline 코드.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOCT6lhtZ70m8kZwPeaD36x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100jy/voice_competition/blob/master/baseline_%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYh7Mne7eTnT",
        "colab_type": "text"
      },
      "source": [
        "구글 드라이브 연동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wlt388hdkj1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "90da0712-75da-4ddc-a113-17c7259f3e6a"
      },
      "source": [
        "#구글 드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-MsxJu1hcs1",
        "colab_type": "text"
      },
      "source": [
        "모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxxxC8E2fJt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from scipy.io import wavfile\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Flatten, BatchNormalization,Dropout, Activation\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFW6VCtBhwgr",
        "colab_type": "text"
      },
      "source": [
        "# 음성에서 정형 데이터화\n",
        "\n",
        "1. 음성신호 상태로 이용하는 방법 \n",
        "2. MFCC이용하는 방법\n",
        "3. spectogram 이용하는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_zJ_GvqhmSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 로드 함수 정의 \n",
        "def make_data(datalist, feature = 'signal'):\n",
        "\n",
        "    arr = []\n",
        "    #signal data\n",
        "    if feature == 'signal':\n",
        "        for file in tqdm(datalist):\n",
        "            fs, data = wavfile.read(file)\n",
        "            arr.append(data)\n",
        "  \n",
        "    #spectogam data\n",
        "    elif feature == 'spectogram':\n",
        "        for file in tqdm(datalist):\n",
        "            x, sr = librosa.load(file)\n",
        "            spec = librosa.stft(x)\n",
        "            arr.append(spec.flatten())\n",
        "  \n",
        "    #MFCC data\n",
        "    elif feature == 'MFCC':\n",
        "        for file in tqdm(datalist):\n",
        "            x, sr = librosa.load(file)\n",
        "            mfcc = librosa.feature.mfcc(x, sr=sr, n_mfcc=40, fmax=3000)\n",
        "            arr.append(mfcc.flatten())\n",
        "  \n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    result = np.array(arr)\n",
        "    \n",
        "    return result "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0lPgXVen8S4",
        "colab_type": "text"
      },
      "source": [
        "VAD하면 성능이 더 좋지 않을까???\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRbrZJizR59u",
        "colab_type": "text"
      },
      "source": [
        "트레인 셋 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbisCnEyuA5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#signal 형태로 사용\n",
        "raw_data = glob('data/train/*.wav')\n",
        "#signal\n",
        "signal = make_data(raw_data)\n",
        "pd.DataFrame(signal).to_pickle('data/x_trian.pickle')\n",
        "#specto\n",
        "specto = make_data(raw_data, feature =  'spectogram')\n",
        "pd.DataFrame(specto).to_pickle('data/x_trian_spectogram.pickle')\n",
        "#MFCC\n",
        "MFCC = make_data(raw_data, feature =  'MFCC')\n",
        "pd.DataFrame(MFCC).to_pickle('data/x_trian_MFCC.pickle')\n",
        "#feature = \n",
        "#x_train = pd.read_csv('data/train/x_train_{}.pickle'.format(feature))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxOE6GDvR8-P",
        "colab_type": "text"
      },
      "source": [
        "테스트 셋 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNsTiFuMDIlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#signal 형태로 사용\n",
        "raw_data = glob('drive/My Drive/data/test/*.wav')\n",
        "#signal\n",
        "signal = make_data(raw_data)\n",
        "pd.DataFrame(signal).to_pickle('drive/My Drive/data/x_test.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKSKn5RaYEIb",
        "colab_type": "text"
      },
      "source": [
        "데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsBCdFuFQXkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#원본\n",
        "x_train = pd.read_pickle('drive/My Drive/data/x_trian.pickle')\n",
        "x_train = x_train.values\n",
        "## ram 충분....\n",
        "#x_train = x_train[:,::8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlqitTwbYGjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MFCC\n",
        "x_train = pd.read_pickle('drive/My Drive/data/x_trian_MFCC.pickle')\n",
        "x_train = x_train.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c55wRapHkeIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (0,1)로 정규화\n",
        "x_train = list((map(lambda x : x / max(x),x_train)))\n",
        "x_train =  np.array(x_train)\n",
        "# 모델 넣기위한 reshape\n",
        "## 채널 늘려보는 것도 의미있을듯...\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbmyjt4jRBcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f0839cf-e1a4-426d-cd5e-b4d989ce7cd0"
      },
      "source": [
        "y_train = pd.read_csv('drive/My Drive/data/train_answer.csv',index_col=0)\n",
        "y_train = y_train.values\n",
        "\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100000, 16000), (100000, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_napOUGrhgEh",
        "colab_type": "text"
      },
      "source": [
        "# model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHxgjDB7o1qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN\n",
        "model = Sequential()\n",
        "model.add(Conv1D(16,32,activation='relu', input_shape = (x_train.shape[1], x_train.shape[2])))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(16,32,activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(16,32,activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(16,32,activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(16,32,activation='relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected layer\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(30, activation='softmax'))\n",
        "model.compile(loss=keras.losses.KLDivergence(), optimizer = 'adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn4TaE62wDAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c139b10-21f5-4b37-c2d9-7d16fc06196c"
      },
      "source": [
        "x_train.shape[1], x_train.shape[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 44)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drelnMIuhrze",
        "colab_type": "text"
      },
      "source": [
        "# model architecture fot 2D data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ixLbE3Thord",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "acab5d29-a6c0-4883-c0c6-bb78a8bab5aa"
      },
      "source": [
        "## padding same, dropout 0.3\n",
        "x_train = x_train.reshape(x_train.shape[0], 40, -1,1)\n",
        "#CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size = (3,3), strides = (1,1), padding='valid', input_shape = (x_train.shape[1], x_train.shape[2],1)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size = (3,3), strides = (1,1), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size = (3,3), strides = (1,1), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "'''\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(512, kernel_size = (3,3), strides = (1,1),activation='relu'))\n",
        "'''\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected layer\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(30, activation='softmax'))\n",
        "model.compile(loss=keras.losses.KLDivergence(), optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_160 (Conv2D)          (None, 38, 42, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_141 (MaxPoolin (None, 19, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_161 (Conv2D)          (None, 19, 21, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_142 (MaxPoolin (None, 9, 10, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_162 (Conv2D)          (None, 9, 10, 128)        147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_143 (MaxPoolin (None, 4, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 512)               1311232   \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 30)                7710      \n",
            "=================================================================\n",
            "Total params: 1,738,142\n",
            "Trainable params: 1,738,142\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A59Z8Q4s182U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "9515f836-1503-4232-c659-98923169303a"
      },
      "source": [
        "## padding valid, dropout 0.5\n",
        "x_train = x_train.reshape(x_train.shape[0], 40, -1,1)\n",
        "#CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size = (3,3), strides = (1,1),activation='relu', input_shape = (x_train.shape[1], x_train.shape[2],1)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size = (3,3), strides = (1,1),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size = (3,3), strides = (1,1),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected layer\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(30, activation='softmax'))\n",
        "model.compile(loss=keras.losses.KLDivergence(), optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_163 (Conv2D)          (None, 38, 42, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_144 (MaxPoolin (None, 19, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_164 (Conv2D)          (None, 17, 19, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_145 (MaxPoolin (None, 8, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_165 (Conv2D)          (None, 6, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_146 (MaxPoolin (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_28 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 512)               590336    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 30)                7710      \n",
            "=================================================================\n",
            "Total params: 1,017,246\n",
            "Trainable params: 1,017,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYLd0VgdpXWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "bedf266c-773f-4218-b6a3-50c10d4696ab"
      },
      "source": [
        "### padding valid, dropout 0.5, shorter fully-conneted\n",
        "x_train = x_train.reshape(x_train.shape[0], 40, -1,1)\n",
        "#CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size = (3,3), strides = (1,1),activation='relu', input_shape = (x_train.shape[1], x_train.shape[2],1)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size = (3,3), strides = (1,1),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size = (3,3), strides = (1,1),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#fully connected layer\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(30, activation='softmax'))\n",
        "model.compile(loss=keras.losses.KLDivergence(), optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_172 (Conv2D)          (None, 38, 42, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_153 (MaxPoolin (None, 19, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_173 (Conv2D)          (None, 17, 19, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_154 (MaxPoolin (None, 8, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_174 (Conv2D)          (None, 6, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_155 (MaxPoolin (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_31 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 512)               590336    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 30)                15390     \n",
            "=================================================================\n",
            "Total params: 827,806\n",
            "Trainable params: 827,806\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cq_NezXg_yH",
        "colab_type": "text"
      },
      "source": [
        "# compile for signal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSSGxW6Chpuk",
        "colab_type": "text"
      },
      "source": [
        "성능 구리다...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iiSqjJ_g0LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = 'drive/My Drive/data/model_signal/'\n",
        "if not os.path.exists(model_path):\n",
        "  os.mkdir(model_path)\n",
        "\n",
        "# validattion 기준 모델 갱신\n",
        "model_file = model_path + 'epoch_{epoch:03d}_val_{val_loss:3f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath = model_file, monitor = 'val_loss', verbose = 1, save_best_only =True)\n",
        "\n",
        "#10회간 validatation 좋아지지 않으면 early stop\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 100, batch_size = 256, validation_split = 0.2, shuffle = True,\n",
        "                    callbacks = [checkpoint, early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kM66x-GjsPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련 결과를 확인합니다.\n",
        "# validation 성능 fool하다....\n",
        "plt.plot(history.epoch, history.history['loss'], '-o', label='training_loss')\n",
        "plt.plot(history.epoch, history.history['val_loss'], '-o', label='validation_loss')\n",
        "plt.legend()\n",
        "plt.xlim(left=0)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JQjUYThjyHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 검증 wav 파일로부터 Feature를 만듭니다.\n",
        "x_test = pd.read_pickle('drive/My Drive/data/x_test_normalized.pickle')\n",
        "x_test = x_test.values\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
        "\n",
        "# 가장 좋은 모델의 weight를 불러옵니다.\n",
        "weigth_file = glob('drive/My Drive/data/model/*.hdf5')[-1]\n",
        "print(weigth_file)\n",
        "model.load_weights(weigth_file)\n",
        "\n",
        "# 예측 수행\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# 예측 결과로 제출 파일을 생성합니다.\n",
        "submission = pd.read_csv('drive/My Drive/data/submission.csv', index_col=0)\n",
        "submission.loc[:, :] = y_pred\n",
        "submission.to_csv('drive/My Drive/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO0grTu7hDr6",
        "colab_type": "text"
      },
      "source": [
        "# compile for MFCC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ub9_9IZxTSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8cb01e1-e657-40d4-8aae-e7f9d17201e5"
      },
      "source": [
        "model_path = 'drive/My Drive/data/model/'\n",
        "if not os.path.exists(model_path):\n",
        "  os.mkdir(model_path)\n",
        "\n",
        "# validattion 기준 모델 갱신\n",
        "model_file = model_path + 'epoch_{epoch:03d}_val_{val_loss:3f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath = model_file, monitor = 'val_loss', verbose = 1, save_best_only =True)\n",
        "\n",
        "#10회간 validatation 좋아지지 않으면 early stop\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 100, batch_size = 64, validation_split = 0.2, shuffle = True,\n",
        "                    callbacks = [checkpoint, early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80000 samples, validate on 20000 samples\n",
            "Epoch 1/100\n",
            "80000/80000 [==============================] - 49s 612us/step - loss: 1.7428 - val_loss: 2.9026\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.90256, saving model to drive/My Drive/data/model/epoch_001_val_2.902563.hdf5\n",
            "Epoch 2/100\n",
            "80000/80000 [==============================] - 48s 594us/step - loss: 1.5692 - val_loss: 2.1765\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.90256 to 2.17647, saving model to drive/My Drive/data/model/epoch_002_val_2.176467.hdf5\n",
            "Epoch 3/100\n",
            "80000/80000 [==============================] - 47s 591us/step - loss: 1.4897 - val_loss: 2.0291\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.17647 to 2.02906, saving model to drive/My Drive/data/model/epoch_003_val_2.029064.hdf5\n",
            "Epoch 4/100\n",
            "80000/80000 [==============================] - 47s 591us/step - loss: 1.4333 - val_loss: 1.9876\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.02906 to 1.98765, saving model to drive/My Drive/data/model/epoch_004_val_1.987646.hdf5\n",
            "Epoch 5/100\n",
            "80000/80000 [==============================] - 48s 597us/step - loss: 1.3902 - val_loss: 1.8043\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.98765 to 1.80431, saving model to drive/My Drive/data/model/epoch_005_val_1.804311.hdf5\n",
            "Epoch 6/100\n",
            "80000/80000 [==============================] - 47s 590us/step - loss: 1.3538 - val_loss: 1.8446\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.80431\n",
            "Epoch 7/100\n",
            "80000/80000 [==============================] - 49s 609us/step - loss: 1.3260 - val_loss: 1.6129\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.80431 to 1.61292, saving model to drive/My Drive/data/model/epoch_007_val_1.612917.hdf5\n",
            "Epoch 8/100\n",
            "80000/80000 [==============================] - 47s 593us/step - loss: 1.3026 - val_loss: 1.6482\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.61292\n",
            "Epoch 9/100\n",
            "80000/80000 [==============================] - 47s 588us/step - loss: 1.2815 - val_loss: 1.6136\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.61292\n",
            "Epoch 10/100\n",
            "80000/80000 [==============================] - 46s 581us/step - loss: 1.2614 - val_loss: 1.5302\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.61292 to 1.53024, saving model to drive/My Drive/data/model/epoch_010_val_1.530243.hdf5\n",
            "Epoch 11/100\n",
            "80000/80000 [==============================] - 47s 584us/step - loss: 1.2446 - val_loss: 1.5156\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.53024 to 1.51563, saving model to drive/My Drive/data/model/epoch_011_val_1.515627.hdf5\n",
            "Epoch 12/100\n",
            "80000/80000 [==============================] - 47s 582us/step - loss: 1.2292 - val_loss: 1.5900\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.51563\n",
            "Epoch 13/100\n",
            "80000/80000 [==============================] - 47s 588us/step - loss: 1.2145 - val_loss: 1.5496\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.51563\n",
            "Epoch 14/100\n",
            "80000/80000 [==============================] - 48s 606us/step - loss: 1.2008 - val_loss: 1.4646\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.51563 to 1.46460, saving model to drive/My Drive/data/model/epoch_014_val_1.464597.hdf5\n",
            "Epoch 15/100\n",
            "80000/80000 [==============================] - 47s 584us/step - loss: 1.1899 - val_loss: 1.4649\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.46460\n",
            "Epoch 16/100\n",
            "80000/80000 [==============================] - 47s 586us/step - loss: 1.1793 - val_loss: 1.5784\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.46460\n",
            "Epoch 17/100\n",
            "80000/80000 [==============================] - 47s 593us/step - loss: 1.1694 - val_loss: 1.6040\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.46460\n",
            "Epoch 18/100\n",
            "80000/80000 [==============================] - 47s 592us/step - loss: 1.1594 - val_loss: 1.4155\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.46460 to 1.41551, saving model to drive/My Drive/data/model/epoch_018_val_1.415506.hdf5\n",
            "Epoch 19/100\n",
            "80000/80000 [==============================] - 47s 590us/step - loss: 1.1494 - val_loss: 1.4670\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.41551\n",
            "Epoch 20/100\n",
            "80000/80000 [==============================] - 49s 611us/step - loss: 1.1409 - val_loss: 1.5762\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.41551\n",
            "Epoch 21/100\n",
            "80000/80000 [==============================] - 48s 595us/step - loss: 1.1314 - val_loss: 1.6135\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.41551\n",
            "Epoch 22/100\n",
            "80000/80000 [==============================] - 47s 588us/step - loss: 1.1244 - val_loss: 1.5134\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.41551\n",
            "Epoch 23/100\n",
            "80000/80000 [==============================] - 47s 582us/step - loss: 1.1155 - val_loss: 1.5959\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.41551\n",
            "Epoch 24/100\n",
            "80000/80000 [==============================] - 47s 590us/step - loss: 1.1092 - val_loss: 1.4340\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.41551\n",
            "Epoch 25/100\n",
            "80000/80000 [==============================] - 47s 581us/step - loss: 1.1019 - val_loss: 1.4558\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.41551\n",
            "Epoch 26/100\n",
            "80000/80000 [==============================] - 47s 591us/step - loss: 1.0938 - val_loss: 1.4359\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.41551\n",
            "Epoch 27/100\n",
            "80000/80000 [==============================] - 48s 602us/step - loss: 1.0883 - val_loss: 1.4996\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.41551\n",
            "Epoch 28/100\n",
            "80000/80000 [==============================] - 47s 590us/step - loss: 1.0822 - val_loss: 1.4464\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.41551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTa3_yH3yc2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "5ce32ac4-26e9-455f-e9e1-ac43d7b75037"
      },
      "source": [
        "# 훈련 결과를 확인합니다.\n",
        "# validation 성능 fool하다....\n",
        "plt.plot(history.epoch, history.history['loss'], '-o', label='training_loss')\n",
        "plt.plot(history.epoch, history.history['val_loss'], '-o', label='validation_loss')\n",
        "plt.legend()\n",
        "plt.xlim(left=0)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3updRLHBYWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67ec72be-1881-4610-beb3-1b437eacaf62"
      },
      "source": [
        "# 검증 wav 파일로부터 Feature를 만듭니다.\n",
        "\n",
        "x_test = pd.read_pickle('drive/My Drive/data/x_test_MFCC.pickle')\n",
        "x_test = x_test.values\n",
        "x_test = list((map(lambda x : x / max(x),x_test)))\n",
        "x_test =  np.array(x_test)\n",
        "'''\n",
        "x_test = pd.read_pickle('drive/My Drive/data/x_test_normalized.pickle')\n",
        "x_test = x_test.values\n",
        "#x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
        "'''\n",
        "x_test = x_test.reshape(x_test.shape[0], 40,-1, 1)\n",
        "\n",
        "# 가장 좋은 모델의 weight를 불러옵니다.\n",
        "weigth_file = glob('drive/My Drive/data/model/*.hdf5')[-1]\n",
        "print(weigth_file)\n",
        "model.load_weights(weigth_file)\n",
        "\n",
        "# 예측 수행\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# 예측 결과로 제출 파일을 생성합니다.\n",
        "submission = pd.read_csv('drive/My Drive/data/submission.csv', index_col=0)\n",
        "submission.loc[:, :] = y_pred\n",
        "submission.to_csv('drive/My Drive/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/data/model/epoch_018_val_1.415506.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm0JUuVtyE7o",
        "colab_type": "text"
      },
      "source": [
        "# compile for MFCC_2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OcqbI31yCB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca1e74ad-8551-4e54-cdcd-9dd288d7c473"
      },
      "source": [
        "model_path = 'drive/My Drive/data/model_2D/'\n",
        "if not os.path.exists(model_path):\n",
        "  os.mkdir(model_path)\n",
        "\n",
        "# validattion 기준 모델 갱신\n",
        "model_file = model_path + 'epoch_{epoch:03d}_val_{val_loss:3f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath = model_file, monitor = 'val_loss', verbose = 1, save_best_only =True)\n",
        "\n",
        "#10회간 validatation 좋아지지 않으면 early stop\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 100, batch_size = 64, validation_split = 0.2, shuffle = True,\n",
        "                    callbacks = [checkpoint, early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80000 samples, validate on 20000 samples\n",
            "Epoch 1/100\n",
            "80000/80000 [==============================] - 53s 667us/step - loss: 1.8711 - val_loss: 1.7115\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.71150, saving model to drive/My Drive/data/model_2D/epoch_001_val_1.711496.hdf5\n",
            "Epoch 2/100\n",
            "80000/80000 [==============================] - 52s 655us/step - loss: 1.6859 - val_loss: 1.5656\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.71150 to 1.56564, saving model to drive/My Drive/data/model_2D/epoch_002_val_1.565645.hdf5\n",
            "Epoch 3/100\n",
            "80000/80000 [==============================] - 54s 672us/step - loss: 1.6013 - val_loss: 1.5054\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.56564 to 1.50544, saving model to drive/My Drive/data/model_2D/epoch_003_val_1.505440.hdf5\n",
            "Epoch 4/100\n",
            "80000/80000 [==============================] - 52s 655us/step - loss: 1.5496 - val_loss: 1.4652\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.50544 to 1.46521, saving model to drive/My Drive/data/model_2D/epoch_004_val_1.465210.hdf5\n",
            "Epoch 5/100\n",
            "80000/80000 [==============================] - 52s 655us/step - loss: 1.5151 - val_loss: 1.4369\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.46521 to 1.43688, saving model to drive/My Drive/data/model_2D/epoch_005_val_1.436881.hdf5\n",
            "Epoch 6/100\n",
            "80000/80000 [==============================] - 54s 669us/step - loss: 1.4895 - val_loss: 1.4169\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.43688 to 1.41695, saving model to drive/My Drive/data/model_2D/epoch_006_val_1.416950.hdf5\n",
            "Epoch 7/100\n",
            "80000/80000 [==============================] - 52s 655us/step - loss: 1.4701 - val_loss: 1.4008\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.41695 to 1.40077, saving model to drive/My Drive/data/model_2D/epoch_007_val_1.400772.hdf5\n",
            "Epoch 8/100\n",
            "80000/80000 [==============================] - 53s 662us/step - loss: 1.4543 - val_loss: 1.4058\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.40077\n",
            "Epoch 9/100\n",
            "80000/80000 [==============================] - 54s 673us/step - loss: 1.4423 - val_loss: 1.3922\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.40077 to 1.39220, saving model to drive/My Drive/data/model_2D/epoch_009_val_1.392201.hdf5\n",
            "Epoch 10/100\n",
            "80000/80000 [==============================] - 52s 656us/step - loss: 1.4322 - val_loss: 1.3777\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.39220 to 1.37771, saving model to drive/My Drive/data/model_2D/epoch_010_val_1.377711.hdf5\n",
            "Epoch 11/100\n",
            "80000/80000 [==============================] - 52s 648us/step - loss: 1.4218 - val_loss: 1.3687\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.37771 to 1.36875, saving model to drive/My Drive/data/model_2D/epoch_011_val_1.368749.hdf5\n",
            "Epoch 12/100\n",
            "80000/80000 [==============================] - 52s 654us/step - loss: 1.4135 - val_loss: 1.3648\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.36875 to 1.36478, saving model to drive/My Drive/data/model_2D/epoch_012_val_1.364777.hdf5\n",
            "Epoch 13/100\n",
            "80000/80000 [==============================] - 52s 650us/step - loss: 1.4073 - val_loss: 1.3588\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.36478 to 1.35875, saving model to drive/My Drive/data/model_2D/epoch_013_val_1.358753.hdf5\n",
            "Epoch 14/100\n",
            "80000/80000 [==============================] - 53s 657us/step - loss: 1.3989 - val_loss: 1.3595\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.35875\n",
            "Epoch 15/100\n",
            "80000/80000 [==============================] - 54s 677us/step - loss: 1.3941 - val_loss: 1.3700\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.35875\n",
            "Epoch 16/100\n",
            "80000/80000 [==============================] - 54s 675us/step - loss: 1.3875 - val_loss: 1.3520\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.35875 to 1.35203, saving model to drive/My Drive/data/model_2D/epoch_016_val_1.352031.hdf5\n",
            "Epoch 17/100\n",
            "80000/80000 [==============================] - 54s 672us/step - loss: 1.3835 - val_loss: 1.3543\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.35203\n",
            "Epoch 18/100\n",
            "80000/80000 [==============================] - 53s 660us/step - loss: 1.3789 - val_loss: 1.3478\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.35203 to 1.34781, saving model to drive/My Drive/data/model_2D/epoch_018_val_1.347809.hdf5\n",
            "Epoch 19/100\n",
            "80000/80000 [==============================] - 55s 692us/step - loss: 1.3722 - val_loss: 1.3523\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.34781\n",
            "Epoch 20/100\n",
            "80000/80000 [==============================] - 57s 708us/step - loss: 1.3695 - val_loss: 1.3465\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.34781 to 1.34655, saving model to drive/My Drive/data/model_2D/epoch_020_val_1.346547.hdf5\n",
            "Epoch 21/100\n",
            "80000/80000 [==============================] - 54s 670us/step - loss: 1.3662 - val_loss: 1.3471\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.34655\n",
            "Epoch 22/100\n",
            "80000/80000 [==============================] - 53s 664us/step - loss: 1.3611 - val_loss: 1.3503\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.34655\n",
            "Epoch 23/100\n",
            "80000/80000 [==============================] - 54s 674us/step - loss: 1.3582 - val_loss: 1.3399\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.34655 to 1.33994, saving model to drive/My Drive/data/model_2D/epoch_023_val_1.339941.hdf5\n",
            "Epoch 24/100\n",
            "80000/80000 [==============================] - 53s 669us/step - loss: 1.3548 - val_loss: 1.3517\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.33994\n",
            "Epoch 25/100\n",
            "80000/80000 [==============================] - 53s 667us/step - loss: 1.3515 - val_loss: 1.3369\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.33994 to 1.33690, saving model to drive/My Drive/data/model_2D/epoch_025_val_1.336903.hdf5\n",
            "Epoch 26/100\n",
            "80000/80000 [==============================] - 55s 685us/step - loss: 1.3495 - val_loss: 1.3438\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.33690\n",
            "Epoch 27/100\n",
            "80000/80000 [==============================] - 54s 669us/step - loss: 1.3467 - val_loss: 1.3554\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.33690\n",
            "Epoch 28/100\n",
            "80000/80000 [==============================] - 56s 700us/step - loss: 1.3422 - val_loss: 1.3428\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.33690\n",
            "Epoch 29/100\n",
            "80000/80000 [==============================] - 54s 674us/step - loss: 1.3416 - val_loss: 1.3469\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.33690\n",
            "Epoch 30/100\n",
            "42496/80000 [==============>...............] - ETA: 23s - loss: 1.3348"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-b03ac8779f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m history = model.fit(x_train, y_train, epochs = 100, batch_size = 64, validation_split = 0.2, shuffle = True,\n\u001b[0;32m---> 13\u001b[0;31m                     callbacks = [checkpoint, early_stop])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VggoeXOnytZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련 결과를 확인합니다.\n",
        "# validation 성능 fool하다....\n",
        "plt.plot(history.epoch, history.history['loss'], '-o', label='training_loss')\n",
        "plt.plot(history.epoch, history.history['val_loss'], '-o', label='validation_loss')\n",
        "plt.legend()\n",
        "plt.xlim(left=0)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMFfoQImzwUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_test 문제있는거 같음...\n",
        "# 검증 wav 파일로부터 Feature를 만듭니다.\n",
        "x_test = pd.read_pickle('drive/My Drive/data/x_test_MFCC.pickle')\n",
        "x_test = x_test.values\n",
        "x_test = list((map(lambda x : x / max(x),x_test)))\n",
        "x_test =  np.array(x_test)\n",
        "x_test = x_test.reshape(x_test.shape[0], 40,-1, 1)\n",
        "\n",
        "# 가장 좋은 모델의 weight를 불러옵니다.\n",
        "weigth_file = glob('drive/My Drive/data/model_2D/*.hdf5')[-1]\n",
        "print(weigth_file)\n",
        "model.load_weights(weigth_file)\n",
        "\n",
        "# 예측 수행\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# 예측 결과로 제출 파일을 생성합니다.\n",
        "submission = pd.read_csv('drive/My Drive/data/submission.csv', index_col=0)\n",
        "submission.loc[:, :] = y_pred\n",
        "submission.to_csv('drive/My Drive/data/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvTUMn6yhI7t",
        "colab_type": "text"
      },
      "source": [
        "# 결과 구간화\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYMro9QUhPky",
        "colab_type": "text"
      },
      "source": [
        "행합이 1이 아닌 결과 값이 많음....(처리 필요함..)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsKgW3WJc3hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_step(vec):\n",
        "  for i,con in enumerate(vec):\n",
        "    interval = 0.125\n",
        "    if 0<= con <interval:\n",
        "      vec[i] = 0\n",
        "    elif interval<= con < interval*2:\n",
        "      vec[i] = 0.25\n",
        "    elif interval*2<= con < interval*3:\n",
        "      vec[i] = 0.75\n",
        "    else:\n",
        "      vec[i] = 1\n",
        "    \n",
        "    return vec\n",
        "\n",
        "submission_step = list(map(make_step, submission.values))\n",
        "submission_step = np.array(submission_step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSpbeFsVnGxj",
        "colab_type": "text"
      },
      "source": [
        "# 7/20 \n",
        "**모델** : epoch_008_val_**1.724779**.hdf5(1D model)\n",
        "  \n",
        "**데이터**: x_trian_MFCC\n",
        "  \n",
        "**score** : ? (test set 잘못됨..) \n",
        "\n",
        "--------------------------------------\n",
        "\n",
        "**모델** : epoch_015_val_**1.452905**.hdf5(2D model)\n",
        "  \n",
        "**데이터**: x_trian_MFCC\n",
        "  \n",
        "**score** : ?(test set 잘못됨..)\n",
        "\n",
        "--------------------------------------\n",
        "\n",
        "**모델** : epoch_018_val_**1.415506**.hdf5(2D model)\n",
        "  \n",
        "**데이터**: x_trian_MFCC\n",
        "  \n",
        "**score** : **1.4672**\n"
      ]
    }
  ]
}