{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "보류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6206exZjDwSe5hGwSmNps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100jy/voice_competition/blob/master/%EB%B3%B4%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynKKx1Ur7np2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inception_with_l2_regulizer\n",
        "def inception_l2_model(input_shape):\n",
        "  def inception_module(x, o_1=64,r_3 =64, o_3 =128,r_5=16,o_5=32,pool=32):\n",
        "    #size_1 filter\n",
        "    x_1 = Conv2D(o_1,1,padding='same', kernel_regularizer=regularizers.l2(0.0005), bias_regularizer=regularizers.l2(0.0005))(x)\n",
        "    '''\n",
        "    #size_1 + size_1 filter\n",
        "    x_2 = Conv2D(r_3,1,padding='same')(x)\n",
        "    x_2 = Conv2D(o_3,1,padding='same')(x_2)\n",
        "    '''\n",
        "    #size_1 + size_5 filter\n",
        "    x_3 = Conv2D(r_5,1,padding='same', kernel_regularizer=regularizers.l2(0.0005), bias_regularizer=regularizers.l2(0.0005))(x)\n",
        "    x_3 = Conv2D(o_5,5,padding='same', kernel_regularizer=regularizers.l2(0.0005), bias_regularizer=regularizers.l2(0.0005))(x_3)\n",
        "\n",
        "    #pooling\n",
        "    x_4 = MaxPooling2D(pool_size = (3,3),strides =1,padding='same')(x)\n",
        "    x_4 = Conv2D(pool, 1, padding='same')(x_4)\n",
        "\n",
        "    return concatenate([x_1,x_3,x_4])\n",
        "\n",
        "  #DeepCNN with Gelu\n",
        "  def gelu(x):\n",
        "      return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
        "\n",
        "\n",
        "  inp = Input(input_shape) \n",
        "\n",
        "  x = Conv2D(64, (7, 7), strides = 2, padding = \"same\", kernel_regularizer=regularizers.l2(0.0005), bias_regularizer=regularizers.l2(0.0005))(inp)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
        "  x = Conv2D(64, (1, 1), strides = 1, padding = \"same\", kernel_regularizer=regularizers.l2(0.0005), bias_regularizer=regularizers.l2(0.0005))(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = Conv2D(192, (3, 3), strides = 1, padding = \"same\", kernel_regularizer=regularizers.l2(0.0005), bias_regularizer=regularizers.l2(0.0005))(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
        "\n",
        "  x = inception_module(x, o_1=64, r_3=64, o_3=128, r_5=16, o_5=32, pool=32)\n",
        "  x = inception_module(x, o_1=128, r_3=128, o_3=192, r_5=32, o_5=96, pool=64)\n",
        "  x = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
        "  x = inception_module(x, o_1=192, r_3=96, o_3=208, r_5=16, o_5=48, pool=64)\n",
        "  \n",
        "  x = inception_module(x, o_1=160, r_3=112, o_3=224, r_5=24, o_5=64, pool=64)\n",
        "  x = inception_module(x, o_1=128, r_3=128, o_3=256, r_5=24, o_5=64, pool=64)\n",
        "  x = inception_module(x, o_1=112, r_3=144, o_3=288, r_5=32, o_5=64, pool=64)\n",
        "  x = inception_module(x, o_1=256, r_3=160, o_3=320, r_5=32, o_5=128, pool=128)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(x)\n",
        "  x = inception_module(x, o_1=256, r_3=160, o_3=320, r_5=32, o_5=128, pool=128)\n",
        "  x = inception_module(x, o_1=384, r_3=192, o_3=384, r_5=48, o_5=128, pool=128)\n",
        "  \n",
        "\n",
        "  x = AveragePooling2D(pool_size=(2, 2), strides=3)(x)\n",
        "  x = Conv2D(128, (1, 1),padding = \"same\", kernel_regularizer=regularizers.l2(0.0005), bias_regularizer=regularizers.l2(0.0005))(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = Flatten()(x)\n",
        "  #x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.8)(x)\n",
        "\n",
        "  x = Dense(1000)(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = Dropout(0.8)(x)\n",
        "  output = Dense(30, activation = \"softmax\")(x)\n",
        "\n",
        "  return Model(inp,output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yylonrt8Hiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inception_resNet_V2\n",
        "##model architecture\n",
        "def Scaling_Residual(Inception, scale):\n",
        "  x = Lambda(lambda Inception, scale : Inception * scale, arguments={'scale': scale})(Inception)\n",
        "  x = Activation(activation = 'relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def conv2d_bn(x,filters, kernel_size, padding = 'same', strides =(1,1), name = None, activation = 'relu'):\n",
        "  x = Conv2D(filters, kernel_size, strides= strides,padding=padding, use_bias=False)(x)\n",
        "  x = BatchNormalization(scale=False)(x)\n",
        "\n",
        "  if activation != 'None':\n",
        "   x = Activation(activation)(x)\n",
        "\n",
        "  return x \n",
        "\n",
        "def stem(input_tensor, version = 'v2', name = None):\n",
        "  if version == 'I-v4' or version == 'v2':\n",
        "    x = conv2d_bn(input_tensor, 32,(3,3),padding='valid', strides = 2)\n",
        "    x = conv2d_bn(x, 32,(3,3),padding='valid')\n",
        "    x = conv2d_bn(x, 64,(3,3))\n",
        "\n",
        "    branch_1 = MaxPooling2D((3,3),padding = 'valid', strides=2)(x)\n",
        "    branch_2 = conv2d_bn(x,96,(3,3),padding = 'valid', strides=2)\n",
        "    x = Concatenate()([branch_1,branch_2])\n",
        "\n",
        "    branch_1 = conv2d_bn(x,64,(1,1))\n",
        "    branch_1 = conv2d_bn(branch_1,96,(3,3),padding='valid')\n",
        "    branch_2 = conv2d_bn(x,64,(1,1))\n",
        "    branch_2 = conv2d_bn(branch_2,64,(7,1))\n",
        "    branch_2 = conv2d_bn(branch_2,64,(1,7))\n",
        "    branch_2 = conv2d_bn(branch_2,96,(3,3),padding='valid')\n",
        "    x = Concatenate()([branch_1,branch_2])\n",
        "\n",
        "    branch_1 = conv2d_bn(x,192,(3,3),padding = 'valid', strides=2)\n",
        "    branch_2 = MaxPooling2D((3,3),padding = 'valid', strides=2)(x)\n",
        "    x = Concatenate()([branch_1,branch_2])\n",
        "\n",
        "    return x\n",
        " \n",
        "\n",
        "reduction_table = {'v2' : [256,256,384,384]}\n",
        "\n",
        "\n",
        "\n",
        "def Reduction_A(input_tensor, version='v2', name=None):\n",
        "  k,l,m,n = reduction_table[version]\n",
        "\n",
        "  branch_1 = MaxPooling2D((3,3),padding='valid',strides=2)(input_tensor)\n",
        "\n",
        "  branch_2 = conv2d_bn(input_tensor, n, (3,3), padding  = 'valid', strides=2)\n",
        "\n",
        "  branch_3 = conv2d_bn(input_tensor, k, (1,1))\n",
        "  branch_3 = conv2d_bn(branch_3, l, (3,3))\n",
        "  branch_3 = conv2d_bn(branch_3, m, (3,3), padding  = 'valid', strides=2)\n",
        "\n",
        "  filter_concat = Concatenate()([branch_1,branch_2,branch_3])\n",
        "\n",
        "  return filter_concat \n",
        "  \n",
        "def Reduction_B(input_tensor, version='v2', name=None):\n",
        "\n",
        "  branch_1 = MaxPooling2D((3,3),padding='valid',strides=2)(input_tensor)\n",
        "\n",
        "  branch_2 = conv2d_bn(input_tensor, 256, (1,1))\n",
        "  branch_2 = conv2d_bn(branch_2, 384, (3,3), padding  = 'valid', strides=2)\n",
        "\n",
        "  branch_3 = conv2d_bn(input_tensor, 256, (1,1))\n",
        "  branch_3 = conv2d_bn(branch_3, 288, (3,3), padding  = 'valid', strides=2)\n",
        "  \n",
        "  branch_4 = conv2d_bn(input_tensor, 256, (1,1))\n",
        "  branch_4 = conv2d_bn(branch_4, 288, (3,3))\n",
        "  branch_4 = conv2d_bn(branch_4, 320, (3,3), padding  = 'valid', strides=2)  \n",
        "\n",
        "  filter_concat = Concatenate()([branch_1,branch_2,branch_3,branch_4])\n",
        "\n",
        "  return filter_concat \n",
        "\n",
        "\n",
        "\n",
        "def Inception_ResNet_A(input_tensor, scale = 0.1, version='v2', name = None):\n",
        "  if version == 'v1':\n",
        "    raise ValueError\n",
        "  \n",
        "  else:\n",
        "    branch_1 = conv2d_bn(input_tensor, 32, (1,1))\n",
        "\n",
        "    branch_2 = conv2d_bn(input_tensor, 32, (1,1))\n",
        "    branch_2 = conv2d_bn(branch_2, 32, (3,3))\n",
        "\n",
        "    branch_3 = conv2d_bn(input_tensor, 32, (1,1))\n",
        "    branch_3 = conv2d_bn(branch_3, 48, (3,3))\n",
        "    branch_3 = conv2d_bn(branch_3, 64, (3,3))\n",
        "\n",
        "    branches = Concatenate()([branch_1,branch_2,branch_3])\n",
        "    Inception = conv2d_bn(branches, 384,(1,1), activation = 'None')\n",
        "\n",
        "  scaled_activation = Scaling_Residual(Inception, scale = scale)\n",
        "  residual_connection  = Add()([input_tensor, scaled_activation])\n",
        "\n",
        "  return residual_connection\n",
        "\n",
        "def Inception_ResNet_B(input_tensor, scale = 0.1, version='v2', name = None):\n",
        "  if version == 'v1':\n",
        "    raise ValueError\n",
        "  \n",
        "  else:\n",
        "    branch_1 = conv2d_bn(input_tensor, 192, (1,1))\n",
        "\n",
        "    branch_2 = conv2d_bn(input_tensor, 128, (1,1))\n",
        "    branch_2 = conv2d_bn(branch_2, 160, (1,7))\n",
        "    branch_2 = conv2d_bn(branch_2, 192, (7,1))\n",
        "\n",
        "    branches = Concatenate()([branch_1,branch_2])\n",
        "    Inception = conv2d_bn(branches, 1152,(1,1), activation = 'None')\n",
        "\n",
        "  scaled_activation = Scaling_Residual(Inception, scale = scale)\n",
        "  residual_connection  = Add()([input_tensor, scaled_activation])\n",
        "\n",
        "  return residual_connection\n",
        "  \n",
        "def Inception_ResNet_C(input_tensor, scale = 0.1, version='v2', name = None):\n",
        "  if version == 'v1':\n",
        "    raise ValueError\n",
        "  \n",
        "  else:\n",
        "    branch_1 = conv2d_bn(input_tensor, 192, (1,1))\n",
        "\n",
        "    branch_2 = conv2d_bn(input_tensor, 192, (1,1))\n",
        "    branch_2 = conv2d_bn(branch_2, 224, (1,3))\n",
        "    branch_2 = conv2d_bn(branch_2, 256, (3,1))\n",
        "\n",
        "    branches = Concatenate()([branch_1,branch_2])\n",
        "    Inception = conv2d_bn(branches, 2144,(1,1), activation = 'None')\n",
        "\n",
        "  scaled_activation = Scaling_Residual(Inception, scale = scale)\n",
        "  residual_connection  = Add()([input_tensor, scaled_activation])\n",
        "\n",
        "  return residual_connection\n",
        "\n",
        "\n",
        "def Inception_ResNet(model_input, version = 'v2', classes = 30):\n",
        "  x = stem(model_input, version = version)\n",
        "  \n",
        "  for i in range(5):\n",
        "    x = Inception_ResNet_A(x, scale = 0.17, version =version)\n",
        " \n",
        "  x = Reduction_A(x)\n",
        "  \n",
        "  for i in range(10):\n",
        "    x = Inception_ResNet_B(x, scale = 0.1, version =version)  \n",
        "\n",
        "\n",
        "  x = Reduction_B(x) \n",
        "\n",
        "  for i in range(5):\n",
        "    x = Inception_ResNet_C(x, scale = 0.2, version =version)\n",
        "\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "  x = Dropout(0.8)(x)\n",
        "  \n",
        "  model_output = Dense(classes, activation = 'softmax')(x)\n",
        "  model = Model(model_input,model_output)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKZJ2IP48MHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xception\n",
        "\n",
        "def conv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu', weight_decay=1e-4):\n",
        "    x = Conv2D(filters, kernel_size, padding=padding, strides=strides, kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    if activation:\n",
        "        x = Activation(activation)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def sepconv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu', weight_decay=1e-4, depth_multiplier=1):\n",
        "    x = SeparableConv2D(filters, kernel_size, padding=padding, strides=strides, depth_multiplier=depth_multiplier, depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    if activation:\n",
        "        x = Activation(activation)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def Xception(model_input, classes):\n",
        "    ## Entry flow\n",
        "    x = conv2d_bn(model_input, 32, (3, 3), strides=2) # (299, 299, 3) -> (150, 150, 32)\n",
        "    x = conv2d_bn(x, 64, (3, 3))\n",
        "\n",
        "    for fliters in [128, 256, 728]: # (75, 75, 64) -> (75, 75, 128) -> (38, 38, 256) -> (19, 19, 728)\n",
        "        residual = conv2d_bn(x, fliters, (1, 1), strides=2, activation=None)\n",
        "        \n",
        "        x = Activation(activation='relu')(x)\n",
        "        x = sepconv2d_bn(x, fliters, (3, 3))\n",
        "        x = sepconv2d_bn(x, fliters, (3, 3), activation=None)\n",
        "        x = MaxPooling2D((3, 3), padding='same', strides=2)(x)\n",
        "        \n",
        "        x = Add()([x, residual])\n",
        "        \n",
        "        \n",
        "    ## Middle flow\n",
        "    for i in range(8): # (19, 19, 728)\n",
        "        residual = x\n",
        "        \n",
        "        x = Activation(activation='relu')(x)\n",
        "        x = sepconv2d_bn(x, 728, (3, 3))\n",
        "        x = sepconv2d_bn(x, 728, (3, 3))\n",
        "        x = sepconv2d_bn(x, 728, (3, 3), activation=None)\n",
        "        \n",
        "        x = Add()([x, residual])\n",
        "        \n",
        "        \n",
        "    ## Exit flow\n",
        "    residual = conv2d_bn(x, 1024, (1, 1), strides=2, activation=None) # (19, 19, 728) -> (10, 10, 1024)\n",
        "        \n",
        "    x = Activation(activation='relu')(x)\n",
        "    x = sepconv2d_bn(x, 728, (3, 3))\n",
        "    x = sepconv2d_bn(x, 1024, (3, 3), activation=None) # (19, 19, 728) -> (19, 19, 1024)\n",
        "    x = MaxPooling2D((3, 3), padding='same', strides=2)(x) # (19, 19, 1024) -> (10, 10, 1024)\n",
        "    \n",
        "    x = Add()([x, residual])\n",
        "    \n",
        "    x = sepconv2d_bn(x, 1536, (3, 3))\n",
        "    x = sepconv2d_bn(x, 2048, (3, 3))\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    ## Optinal fully-connected layers\n",
        "       \n",
        "    '''\n",
        "    x = Dense(4096)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation='relu')(x)\n",
        " \n",
        "    x = Dense(4096)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation='relu')(x)\n",
        "    '''\n",
        "    x = Dropout(0.8)(x)\n",
        "\n",
        "    x = Dense(4096)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation='relu')(x)\n",
        "\n",
        "    x = Dropout(0.8)(x)\n",
        "    \n",
        "    model_output = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(model_input, model_output, name='Xception')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cWGi8yz8TJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = 'drive/My Drive/data/model_inception_high_leg_mel_spec/'\n",
        "if not os.path.exists(model_path):\n",
        "  os.mkdir(model_path)\n",
        "\n",
        "# validattion 기준 모델 갱신\n",
        "model_file = model_path + 'epoch_{epoch:03d}_val_{val_loss:3f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath = model_file, monitor = 'val_loss', verbose = 1, save_best_only =True)\n",
        "\n",
        "#lr 조정\n",
        "lrschedule = LearningRateSchedule()\n",
        "\n",
        "#10회간 validatation 좋아지지 않으면 early stop\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = inception_l2_model(input_shape)\n",
        "  model.compile(loss=tf.keras.losses.KLDivergence(), optimizer = 'adam')\n",
        "  #model.summary()\n",
        "  model.load_weights(glob('drive/My Drive/data/model_inception_high_leg_mel_spec/*.hdf5')[-1])\n",
        "  history = model.fit(train_dataset, epochs = 100, validation_data=val_dataset, callbacks = [checkpoint, early_stop,lrschedule])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiFmd5VA8Ubp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model compile\n",
        "input_shape = (299,299,1)\n",
        "model_input = Input(shape = input_shape)\n",
        "optimizer = RMSprop(lr = 0.045, epsilon = 1.0, decay = 0.9)\n",
        "#optimizer = Adam(0.045)\n",
        "model_path = 'drive/My Drive/data/model_inceptionRes_mel_spec/'\n",
        "if not os.path.exists(model_path):\n",
        "  os.mkdir(model_path)\n",
        "\n",
        "# validattion 기준 모델 갱신\n",
        "model_file = model_path + 'epoch_{epoch:03d}_val_{val_loss:3f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath = model_file, monitor = 'val_loss', verbose = 1, save_best_only =True)\n",
        "\n",
        "#10회간 validatation 좋아지지 않으면 early stop\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "#lr 조정\n",
        "lrschedule = LearningRateSchedule()\n",
        "\n",
        "with strategy.scope():\n",
        "  model = Inception_ResNet(model_input)\n",
        "  model.compile(optimizer, loss =tf.keras.losses.KLDivergence())\n",
        "  #model.summary()\n",
        "  #model.load_weights(glob('drive/My Drive/data/model_inceptionRes_mel_spec/*.hdf5')[-1])\n",
        "  history = model.fit(train_dataset, epochs = 100, validation_data=val_dataset,callbacks = [checkpoint, early_stop])#,lrschedule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUOM0NEL8YWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model compile\n",
        "input_shape = (299,299,1)\n",
        "model_input = Input(shape = input_shape)\n",
        "optimizer = SGD(lr=0.01, momentum=0.9)\n",
        "\n",
        "model_path = 'drive/My Drive/data/model_Xception_mel_spec/'\n",
        "if not os.path.exists(model_path):\n",
        "  os.mkdir(model_path)\n",
        "\n",
        "# validattion 기준 모델 갱신\n",
        "model_file = model_path + 'epoch_{epoch:03d}_val_{val_loss:3f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath = model_file, monitor = 'val_loss', verbose = 1, save_best_only =True)\n",
        "\n",
        "#10회간 validatation 좋아지지 않으면 early stop\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "#lr 조정\n",
        "lrschedule = LearningRateSchedule()\n",
        "\n",
        "with strategy.scope():\n",
        "  model_input = Input(shape=input_shape)\n",
        "  model = Xception(model_input, 30)\n",
        "  model.compile(optimizer, loss =tf.keras.losses.KLDivergence())\n",
        "  #model.summary()\n",
        "  #model.load_weights(glob('drive/My Drive/data/model_Xception_mel_spec/*.hdf5')[-1])\n",
        "  history = model.fit(train_dataset, epochs = 100, validation_data=val_dataset,callbacks = [checkpoint, early_stop,lrschedule])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}