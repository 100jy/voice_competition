{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "large_batch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNHO5lh0qY/kaxSzbOh+sz3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100jy/voice_competition/blob/master/large_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DJFtcnt-8fz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "48c327f6-2dce-4cfc-b315-ffab9612eaaf"
      },
      "source": [
        "#구글 드라이브 연동\n",
        "# 클라우드 권한 획득\n",
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from scipy.io import wavfile\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, Callback\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZpe_U6b_fEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_batch(size=1600,seed=100): \n",
        "  GCS_PATH = 'gs://data_bucket_9586/' \n",
        "  AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
        "\n",
        "  def read_train(example):\n",
        "    feature = {'data': tf.io.VarLenFeature(dtype = tf.float32),\n",
        "              'label': tf.io.VarLenFeature(dtype = tf.float32),\n",
        "              }\n",
        "    example = tf.io.parse_single_example(example, feature)\n",
        "\n",
        "    data = tf.sparse.to_dense(example['data'])\n",
        "    label = tf.sparse.to_dense(example['label'])\n",
        "\n",
        "    data = tf.reshape(data,(299,299,1))\n",
        "    label = tf.reshape(label,(30,1))\n",
        "\n",
        "    return data, label\n",
        "\n",
        "  filenames = tf.io.gfile.glob(GCS_PATH + 'train_resize_*.tfrec')[:200000]\n",
        "  spit_len = int(len(filenames) * 0.8)\n",
        "\n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(filenames)\n",
        "\n",
        "  global train_dataset\n",
        "  train_dataset = tf.data.TFRecordDataset(filenames[:spit_len],num_parallel_reads=AUTO)\n",
        "  #batch_size = 3200\n",
        "  train_dataset = train_dataset.map(read_train, num_parallel_calls=AUTO).batch(size).prefetch(1)\n",
        "\n",
        "  global val_dataset\n",
        "  val_dataset = tf.data.TFRecordDataset(filenames[spit_len:],num_parallel_reads=AUTO)\n",
        "  #batch_size = 3200\n",
        "  val_dataset = val_dataset.map(read_train, num_parallel_calls=AUTO).batch(size).prefetch(1)  \n",
        "\n",
        "  for record in train_dataset.take(1):\n",
        "    print(len(record))\n",
        "    input_shape = (record[0].shape[1],record[0].shape[2],record[0].shape[3])\n",
        "    output_shape = record[1].shape[1]\n",
        "\n",
        "  print(input_shape)\n",
        "  print(output_shape)\n",
        "\n",
        "  # Detect hardware\n",
        "  try:\n",
        "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "  except ValueError:\n",
        "    tpu_resolver = None\n",
        "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "  # Select appropriate distribution strategy\n",
        "  if tpu_resolver:\n",
        "    tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu_resolver)\n",
        "\n",
        "  elif len(gpus) > 1:\n",
        "    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "\n",
        "  elif len(gpus) == 1:\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "\n",
        "  else:\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "\n",
        "  return strategy, train_dataset, val_dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvqUF1om_nvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inception_model_2(input_shape):\n",
        "  def inception_module(x, o_1=64,r_3 =64, o_3 =128,r_5=16,o_5=32,pool=32):\n",
        "    #size_1 filter\n",
        "    x_1 = Conv2D(o_1,1,padding='same',kernel_regularizer=l2(1e-5))(x)\n",
        "\n",
        "    #size_1 + size_5 filter\n",
        "    x_3 = Conv2D(r_5,1,padding='same',kernel_regularizer=l2(1e-5))(x)\n",
        "    x_3 = Conv2D(o_5,5,padding='same',kernel_regularizer=l2(1e-5))(x_3)\n",
        "\n",
        "    #pooling\n",
        "    x_4 = MaxPooling2D(pool_size = (3,3),strides =1,padding='same')(x)\n",
        "    x_4 = Conv2D(pool, 1, padding='same',kernel_regularizer=l2(1e-5))(x_4)\n",
        "\n",
        "    return concatenate([x_1,x_3,x_4])\n",
        "\n",
        "  #DeepCNN with Gelu\n",
        "  def gelu(x):\n",
        "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
        "\n",
        "\n",
        "  inp = Input(input_shape) \n",
        "\n",
        "  x = Conv2D(64, (7, 7), strides = 2, padding = \"same\", kernel_initializer='he_normal')(inp)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(64, (1, 1), strides = 1, padding = \"same\", kernel_initializer='he_normal')(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = Conv2D(192, (3, 3), strides = 1, padding = \"same\", kernel_initializer='he_normal')(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = inception_module(x, o_1=64, r_3=64, o_3=128, r_5=16, o_5=32, pool=32)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = inception_module(x, o_1=128, r_3=128, o_3=192, r_5=32, o_5=96, pool=64)\n",
        "  x = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = inception_module(x, o_1=192, r_3=96, o_3=208, r_5=16, o_5=48, pool=64)\n",
        "  x = BatchNormalization()(x)\n",
        "  \n",
        "  x = inception_module(x, o_1=160, r_3=112, o_3=224, r_5=24, o_5=64, pool=64)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = inception_module(x, o_1=128, r_3=128, o_3=256, r_5=24, o_5=64, pool=64)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = inception_module(x, o_1=112, r_3=144, o_3=288, r_5=32, o_5=64, pool=64)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = inception_module(x, o_1=256, r_3=160, o_3=320, r_5=32, o_5=128, pool=128)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = inception_module(x, o_1=256, r_3=160, o_3=320, r_5=32, o_5=128, pool=128)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = inception_module(x, o_1=384, r_3=192, o_3=384, r_5=48, o_5=128, pool=128)\n",
        "  \n",
        "\n",
        "  x = AveragePooling2D(pool_size=(2, 2), strides=3)(x)\n",
        "  x = Conv2D(128, (1, 1),padding = \"same\",kernel_regularizer=l2(1e-5))(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dropout(0.8)(x)\n",
        "\n",
        "\n",
        "  x = Dense(1024)(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.8)(x)\n",
        "\n",
        "\n",
        "  output = Dense(30, activation = \"softmax\")(x)\n",
        "\n",
        "  return Model(inp,output)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "codwx0LWRc-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inception_model_1(input_shape):\n",
        "  def inception_module(x, o_1=64,r_3 =64, o_3 =128,r_5=16,o_5=32,pool=32):\n",
        "    #size_1 filter\n",
        "    x_1 = Conv2D(o_1,1,padding='same',kernel_regularizer=l2(1e-5))(x)\n",
        "\n",
        "    #size_1 + size_5 filter\n",
        "    x_3 = Conv2D(r_5,1,padding='same',kernel_regularizer=l2(1e-5))(x)\n",
        "    x_3 = Conv2D(o_5,5,padding='same',kernel_regularizer=l2(1e-5))(x_3)\n",
        "\n",
        "    #pooling\n",
        "    x_4 = MaxPooling2D(pool_size = (3,3),strides =1,padding='same')(x)\n",
        "    x_4 = Conv2D(pool, 1, padding='same',kernel_regularizer=l2(1e-5))(x_4)\n",
        "\n",
        "    return concatenate([x_1,x_3,x_4])\n",
        "\n",
        "  #DeepCNN with Gelu\n",
        "  def gelu(x):\n",
        "      return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
        "\n",
        "\n",
        "  inp = Input(input_shape) \n",
        "\n",
        "  x = Conv2D(64, (7, 7), strides = 2, padding = \"same\",kernel_regularizer=l2(1e-5))(inp)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
        "  x = Conv2D(64, (1, 1), strides = 1, padding = \"same\",kernel_regularizer=l2(1e-5))(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = Conv2D(192, (3, 3), strides = 1, padding = \"same\",kernel_regularizer=l2(1e-5))(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = MaxPooling2D((3, 3), padding = \"same\", strides = 2)(x)\n",
        "\n",
        "  x = inception_module(x, o_1=64, r_3=64, o_3=128, r_5=16, o_5=32, pool=32)\n",
        "  x = inception_module(x, o_1=128, r_3=128, o_3=192, r_5=32, o_5=96, pool=64)\n",
        "  x = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
        "  x = inception_module(x, o_1=192, r_3=96, o_3=208, r_5=16, o_5=48, pool=64)\n",
        "  \n",
        "  x = inception_module(x, o_1=160, r_3=112, o_3=224, r_5=24, o_5=64, pool=64)\n",
        "  x = inception_module(x, o_1=128, r_3=128, o_3=256, r_5=24, o_5=64, pool=64)\n",
        "  x = inception_module(x, o_1=112, r_3=144, o_3=288, r_5=32, o_5=64, pool=64)\n",
        "  x = inception_module(x, o_1=256, r_3=160, o_3=320, r_5=32, o_5=128, pool=128)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(x)\n",
        "  x = inception_module(x, o_1=256, r_3=160, o_3=320, r_5=32, o_5=128, pool=128)\n",
        "  x = inception_module(x, o_1=384, r_3=192, o_3=384, r_5=48, o_5=128, pool=128)\n",
        "  \n",
        "\n",
        "  x = AveragePooling2D(pool_size=(2, 2), strides=3)(x)\n",
        "  x = Conv2D(128, (1, 1),padding = \"same\",kernel_regularizer=l2(1e-5))(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = Flatten()(x)\n",
        "  #x = Dropout(0.8)(x)\n",
        "\n",
        "  '''\n",
        "  x = Dense(1024)(x)\n",
        "  x = Activation(gelu)(x)\n",
        "  x = Dropout(0.8)(x)\n",
        "  '''\n",
        "\n",
        "  output = Dense(30, activation = \"softmax\")(x)\n",
        "\n",
        "  return Model(inp,output)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIBX5IPPZRxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def conv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu'):\n",
        "    x = Conv2D(filters, kernel_size, kernel_initializer='he_normal', padding=padding, strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if activation:\n",
        "        x = Activation(activation)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "def SE_block(input_tensor, reduction_ratio=16):\n",
        "    ch_input = K.int_shape(input_tensor)[-1]\n",
        "    ch_reduced = ch_input//reduction_ratio\n",
        "    \n",
        "    # Squeeze\n",
        "    x = GlobalAveragePooling2D()(input_tensor) # Eqn.2\n",
        "    \n",
        "    # Excitation\n",
        "    x = Dense(ch_reduced, kernel_initializer='he_normal', activation='relu', use_bias=False)(x) # Eqn.3\n",
        "    x = Dense(ch_input, kernel_initializer='he_normal', activation='sigmoid', use_bias=False)(x) # Eqn.3\n",
        "    \n",
        "    x = Reshape( (1, 1, ch_input) )(x)\n",
        "    x = Multiply()([input_tensor, x]) # Eqn.4\n",
        "    \n",
        "    return x\n",
        "   \n",
        "\n",
        "def SE_residual_block(input_tensor, filter_sizes, strides=1, reduction_ratio=16):\n",
        "    filter_1, filter_2, filter_3 = filter_sizes\n",
        "    \n",
        "    x = conv2d_bn(input_tensor, filter_1, (1, 1), strides=strides)\n",
        "    x = conv2d_bn(x, filter_2, (3, 3))\n",
        "    x = conv2d_bn(x, filter_3, (1, 1), activation=None)\n",
        "    \n",
        "    x = SE_block(x, reduction_ratio)\n",
        "    \n",
        "    projected_input = conv2d_bn(input_tensor, filter_3, (1, 1), strides=strides, activation=None) if K.int_shape(input_tensor)[-1] != filter_3 else input_tensor\n",
        "    shortcut = Add()([projected_input, x])\n",
        "    shortcut = Activation(activation='relu')(shortcut)\n",
        "    \n",
        "    return shortcut\n",
        " \n",
        "\n",
        "def stage_block(input_tensor, filter_sizes, blocks, reduction_ratio=16, stage=''):\n",
        "    strides = 2 if stage != '2' else 1\n",
        "    \n",
        "    x = SE_residual_block(input_tensor, filter_sizes, strides, reduction_ratio) # projection layer\n",
        "\n",
        "    for i in range(blocks-1):\n",
        "        x = SE_residual_block(x, filter_sizes, reduction_ratio=reduction_ratio)\n",
        "    \n",
        "    return x\n",
        "    \n",
        "\n",
        "def SE_ResNet50(input_shape, classes=30):\n",
        "    model_input = Input(input_shape)\n",
        "    stage_1 = conv2d_bn(model_input, 64, (7, 7), strides=2, padding='same') # (112, 112, 64)\n",
        "    stage_1 = MaxPooling2D((3, 3), strides=2, padding='same')(stage_1) # (56, 56, 64)\n",
        "    \n",
        "    stage_2 = stage_block(stage_1, [64, 64, 256], 3, reduction_ratio=16, stage='2')\n",
        "    stage_3 = stage_block(stage_2, [128, 128, 512], 4, reduction_ratio=16, stage='3') # (28, 28, 512)\n",
        "    stage_4 = stage_block(stage_3, [256, 256, 1024], 6, reduction_ratio=16, stage='4') # (14, 14, 1024)\n",
        "    stage_5 = stage_block(stage_4, [512, 512, 2048], 3, reduction_ratio=16, stage='5') # (7, 7, 2048)\n",
        "\n",
        "    gap = GlobalAveragePooling2D()(stage_5)\n",
        "    \n",
        "    model_output = Dense(classes, activation='softmax', kernel_initializer='he_normal')(gap) # 'softmax'\n",
        "    \n",
        "    model = Model(inputs=model_input, outputs=model_output, name='SE-ResNet50')\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZz8kvVW_s6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(id, n_epoch,strategy, train_dataset, val_dataset, road_weight =False,model_name ='m1',optimizer_set='radam'):\n",
        "  model_path = 'drive/My Drive/data/model_high_resol_{}/'.format(id)\n",
        " \n",
        "  if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "   \n",
        "      \n",
        "  # validattion 기준 모델 갱신\n",
        "  model_file = model_path + 'epoch_{epoch:03d}_val_{val_loss:3f}.hdf5'\n",
        "  checkpoint = ModelCheckpoint(filepath = model_file, monitor = 'val_loss', verbose = 1, save_best_only =True)\n",
        "\n",
        "  if optimizer_set == 'radam':\n",
        "    radam = tfa.optimizers.RectifiedAdam()\n",
        "    optimizer  = tfa.optimizers.Lookahead(radam, sync_period=3, slow_step_size=0.5)\n",
        "\n",
        "  elif optimizer_set == 'lamb':\n",
        "    ramb = tfa.optimizers.LAMB()\n",
        "    optimizer  = tfa.optimizers.Lookahead(ramb, sync_period=6, slow_step_size=0.5)\n",
        "\n",
        "\n",
        "  with strategy.scope():\n",
        "    if model_name == 'inception_1':\n",
        "      model = inception_model_1((299,299,1))\n",
        "    elif model_name == 'inception_2':\n",
        "      model = inception_model_2((299,299,1))\n",
        "    elif model_name == 'SE_ResNet':\n",
        "      model = SE_ResNet50((299,299,1),30)\n",
        "    model.compile(loss=tf.keras.losses.KLDivergence(), optimizer = optimizer)\n",
        "    if road_weight:\n",
        "      model.load_weights(glob('drive/My Drive/data/model_high_resol_{}/*.hdf5'.format(id))[-1])\n",
        "    history = model.fit(train_dataset, epochs = n_epoch, validation_data=val_dataset, callbacks = [checkpoint])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEnh55nYS1Ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_k_models(k = 5, model_name='SE_ResNet',batch_size = 64):\n",
        "  for i in range(1,k+1):\n",
        "    strategy, train_dataset, val_dataset = set_batch(batch_size,i)\n",
        "    fit_model(id=i, n_epoch=6, strategy=strategy, train_dataset=train_dataset, val_dataset=val_dataset, road_weight=False ,model_name=model_name)\n",
        "\n",
        "def load_test_set():\n",
        "  GCS_PATH = 'gs://data_bucket_9586/' \n",
        "  AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
        "\n",
        "  def read_test(example):\n",
        "    features = {'data': tf.io.VarLenFeature(dtype = tf.float32)}\n",
        "    example = tf.io.parse_single_example(example, features)\n",
        "\n",
        "    data = tf.sparse.to_dense(example['data'])\n",
        "\n",
        "    data = tf.reshape(data,(299,299,1))\n",
        "    return data\n",
        "    \n",
        "  filenames = tf.io.gfile.glob(GCS_PATH + 'test_*.tfrec')\n",
        "  test_dataset = tf.data.TFRecordDataset(filenames)\n",
        "  test_dataset = test_dataset.map(read_test).batch(128).prefetch(1)\n",
        "\n",
        "  return test_dataset\n",
        "\n",
        "def make_result(model_num):\n",
        "  # 가장 좋은 모델의 weight를 불러옵니다.\n",
        "  input_shape = (299,299,1)\n",
        "  model = SE_ResNet50((299,299,1),30)\n",
        "  weight_file = glob('drive/My Drive/data/model_high_resol_{}/*.hdf5'.format(model_num))[-1]\n",
        "  print(weight_file)\n",
        "  model.load_weights(weight_file)\n",
        "\n",
        "  # 예측 수행\n",
        "  y_pred = model.predict(test_dataset)\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "def k_fold(k, model_name='SE_ResNet',batch_size = 64):\n",
        "  #data load\n",
        "  test_dataset = load_test_set()\n",
        "\n",
        "  #model_fit\n",
        "  fit_k_models(k = 5, model_name=model_name,batch_size = batch_size)\n",
        "\n",
        "  #make_result\n",
        "  submission = pd.read_csv('drive/My Drive/data/submission.csv', index_col=0)\n",
        "  suma = np.zeros_like(submission)\n",
        "  for i in range(1,k):\n",
        "    suma += make_result(i)\n",
        "  submission.loc[:, :] = suma / 5\n",
        "  submission.to_csv('drive/My Drive/data/submission.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JblZ5dinaXkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k_fold(5, model_name='SE_ResNet',batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueKB3a_aY8qn",
        "colab_type": "text"
      },
      "source": [
        "# 8/4\n",
        "--------------------------------------\n",
        "\n",
        "**모델** : SE_ResNet50(5-folds,6 epochs)\n",
        "  \n",
        "**데이터**: x_trian_mel-spectogram(299*299)\n",
        "  \n",
        "**score** : **0.72265 (15위)**\n",
        "\n",
        "**메모** : shifted aug not good, k-folds good, 에폭 더 주면 많이 좋을 듯..\n",
        "\n",
        "**피드백** : 12에폭으로 결과 확인\n",
        "\n",
        "--------------------------------------"
      ]
    }
  ]
}